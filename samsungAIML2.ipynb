{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "from tensorflow.keras import layers, models, initializers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, UpSampling1D, BatchNormalization, Activation, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "from io import BytesIO, StringIO\n",
        "import base64\n",
        "from flask import Flask, render_template, request, redirect, url_for\n",
        "\n",
        "# Initializing \"Flask app\"\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Function to load and preprocess  audio --- \"VCKT dataset\"\n",
        "def load_and_preprocess_vckt_audio(file_path, target_sr=16000, window_size=2048, hop_size=None, upsampling_factor=4):\n",
        "    # Assuming the VCKT dataset format\n",
        "    audio, _ = load_vckt_audio(file_path)  # implementing the load_vckt_audio function\n",
        "    audio = audio / np.max(np.abs(audio))\n",
        "\n",
        "    if hop_size is None:\n",
        "        hop_size = window_size // 2   #To determine how much the window moves forward at each iteration during audio processing...\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(0, len(audio) - window_size, hop_size):\n",
        "        X.append(audio[i:i+window_size])\n",
        "        y.append(audio[i:i+window_size*upsampling_factor:upsampling_factor])\n",
        "\n",
        "    X = np.array(X)[:, :, np.newaxis]\n",
        "    y = np.array(y)[:, :, np.newaxis]\n",
        "\n",
        "    return X, y\n",
        "\n",
        "# Building with the advanced model using --- \"U-Net architecture with spectral normalization\"\n",
        "def build_advanced_model(input_shape):\n",
        "    initializer = initializers.RandomNormal(stddev=0.02)\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # Encoder\n",
        "    model.add(Conv1D(64, kernel_size=9, padding='same', kernel_initializer=initializer, use_bias=False, input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    # Skip connection\n",
        "    skip_connection = Conv1D(64, kernel_size=1, padding='same', kernel_initializer=initializer, use_bias=False)(model.layers[-1].output)\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "    # Decoder\n",
        "    model.add(Conv1D(128, kernel_size=9, padding='same', kernel_initializer=initializer, use_bias=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(UpSampling1D(size=2))\n",
        "\n",
        "    # Skip connection\n",
        "    model.add(Concatenate())\n",
        "    model.add(Conv1D(64, kernel_size=1, padding='same', kernel_initializer=initializer, use_bias=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv1D(1, kernel_size=9, padding='same', activation='tanh'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Function to generate --- \"super-resolved audio\"\n",
        "def generate_super_res_audio(model, input_audio):\n",
        "    input_audio = input_audio[np.newaxis, :, np.newaxis]\n",
        "    output_audio = model.predict(input_audio)\n",
        "    return np.squeeze(output_audio)\n",
        "\n",
        "# Function to calculating --- \"spectrogram difference frames\"\n",
        "def calculate_spectrogram_difference_frames(original_spec, processed_spec):\n",
        "    return original_spec - processed_spec\n",
        "\n",
        "# Function to create and saving the --- \"frequency-domain representations as images\"\n",
        "def save_frequency_representation_images(audio, file_prefix, target_sr=16000):\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    spec = librosa.amplitude_to_db(librosa.stft(audio), ref=np.max)\n",
        "    librosa.display.specshow(spec, y_axis='log', x_axis='time', sr=target_sr)\n",
        "    plt.title(f'{file_prefix} Frequency Representation')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.tight_layout()\n",
        "    img_buffer = BytesIO()\n",
        "    plt.savefig(img_buffer, format='png')\n",
        "    plt.clf()\n",
        "    return img_buffer\n",
        "\n",
        "# Functioning to create HTML content      \"html content\"\n",
        "def create_html_content(file_prefix, audio_files, low_res_audios, super_res_audios, cubic_baseline_audios, high_res_audios, low_res_imgs, super_res_imgs, cubic_baseline_imgs, high_res_imgs):\n",
        "    html_content = f\"\"\"\n",
        "    <html>\n",
        "    <head>\n",
        "      <title>{file_prefix} Audio and Spectrogram Comparison</title>\n",
        "    </head>\n",
        "    <body>\n",
        "      <h2>{file_prefix} Audio and Spectrogram Comparison</h2>\n",
        "    \"\"\"\n",
        "    for i, audio_file in enumerate(audio_files):\n",
        "        html_content += f\"\"\"\n",
        "          <h3>{file_prefix} - Audio File {i + 1}</h3>\n",
        "          <audio controls>\n",
        "            <source src=\"{low_res_audios[i]}\" type=\"audio/wav\">\n",
        "            Your browser does not support the audio element.\n",
        "          </audio>\n",
        "          <audio controls>\n",
        "            <source src=\"{super_res_audios[i]}\" type=\"audio/wav\">\n",
        "            Your browser does not support the audio element.\n",
        "          </audio>\n",
        "          <audio controls>\n",
        "            <source src=\"{cubic_baseline_audios[i]}\" type=\"audio/wav\">\n",
        "            Your browser does not support the audio element.\n",
        "          </audio>\n",
        "          <audio controls>\n",
        "            <source src=\"{high_res_audios[i]}\" type=\"audio/wav\">\n",
        "            Your browser does not support the audio element.\n",
        "          </audio>\n",
        "          <br>\n",
        "          <img src=\"data:image/png;base64,{base64.b64encode(low_res_imgs[i].getvalue()).decode()}\" alt=\"Low Resolution\">\n",
        "          <img src=\"data:image/png;base64,{base64.b64encode(super_res_imgs[i].getvalue()).decode()}\" alt=\"Super Resolution\">\n",
        "          <img src=\"data:image/png;base64,{base64.b64encode(cubic_baseline_imgs[i].getvalue()).decode()}\" alt=\"Cubic Baseline\">\n",
        "          <img src=\"data:image/png;base64,{base64.b64encode(high_res_imgs[i].getvalue()).decode()}\" alt=\"High Resolution\">\n",
        "        \"\"\"\n",
        "    html_content += \"\"\"\n",
        "    </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "    return html_content\n",
        "\n",
        "# Route for --- home page\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template('index.html')\n",
        "\n",
        "# Route to handleing file upload from VCKT dataset\n",
        "@app.route('/upload_vckt', methods=['POST'])\n",
        "def upload_vckt_file():\n",
        "    if 'file' not in request.files:\n",
        "        return redirect(request.url)\n",
        "    file = request.files['file']\n",
        "    if file.filename == '':\n",
        "        return redirect(request.url)\n",
        "\n",
        "    # Save the uploaded file to vckt_uploads folder\n",
        "    file_path = os.path.join('vckt_uploads', file.filename)\n",
        "    file.save(file_path)\n",
        "\n",
        "    # Load and preprocess data from VCKT dataset\n",
        "    X_low_res, _ = load_and_preprocess_vckt_audio(file_path, upsampling_factor=4)\n",
        "\n",
        "    # Build and compile the model\n",
        "    model = build_advanced_model(X_low_res.shape[1:])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss='mae')\n",
        "\n",
        "    # Load pre-trained model\n",
        "    model.load_weights('advanced_audio_super_resolution_model.h5')\n",
        "\n",
        "    # Generating the --- \"super-resolved audio\"\n",
        "    super_res_output = generate_super_res_audio(model, X_low_res[0])\n",
        "\n",
        "    # Cubic Baseline (simple upsampling)\n",
        "    cubic_baseline = librosa.resample(X_low_res[0, :, 0], orig_sr=16000, target_sr=64000, res_type='kaiser_best')\n",
        "\n",
        "    # High Resolution\n",
        "    high_res_output = X_low_res[0, :, 0]\n",
        "\n",
        "    # Save audio signals as audio files\n",
        "    librosa.output.write_wav(f'vckt_uploads/low_resolution_{file.filename}', X_low_res[0, :, 0], sr=16000)\n",
        "    librosa.output.write_wav(f'vckt_uploads/super_resolution_{file.filename}', super_res_output, sr=16000)\n",
        "    librosa.output.write_wav(f'vckt_uploads/cubic_baseline_{file.filename}', cubic_baseline, sr=64000)\n",
        "    librosa.output.write_wav(f'vckt_uploads/high_resolution_{file.filename}', high_res_output, sr=16000)\n",
        "\n",
        "    # Save frequency-domain representations as images\n",
        "    low_res_img = save_frequency_representation_images(X_low_res[0, :, 0], f'vckt_uploads/low_resolution_{file.filename}')\n",
        "    super_res_img = save_frequency_representation_images(super_res_output, f'vckt_uploads/super_resolution_{file.filename}')\n",
        "    cubic_baseline_img = save_frequency_representation_images(cubic_baseline, f'vckt_uploads/cubic_baseline_{file.filename}')\n",
        "    high_res_img = save_frequency_representation_images(high_res_output, f'vckt_uploads/high_resolution_{file.filename}')\n",
        "\n",
        "    # Create HTML --- \"output\"\n",
        "    low_res_audio_file = f'vckt_uploads/low_resolution_{file.filename}'\n",
        "    super_res_audio_file = f'vckt_uploads/super_resolution_{file.filename}'\n",
        "    cubic_baseline_audio_file = f'vckt_uploads/cubic_baseline_{file.filename}'\n",
        "    high_res_audio_file = f'vckt_uploads/high_resolution_{file.filename}'\n",
        "\n",
        "    html_content = create_html_content(file.filename, [file.filename], [low_res_audio_file], [super_res_audio_file], [cubic_baseline_audio_file], [high_res_audio_file],\n",
        "                                       [low_res_img], [super_res_img], [cubic_baseline_img], [high_res_img])\n",
        "\n",
        "    # Save the HTML content to a file in vckt_uploads folder\n",
        "    html_filename = f'vckt_uploads/audio_and_spectrogram_comparison_{file.filename}.html'\n",
        "    with open(html_filename, 'w') as html_file:\n",
        "        html_file.write(html_content)\n",
        "\n",
        "    return redirect(url_for('uploaded_file', filename=file.filename))\n",
        "\n",
        "# Route to display uploaded file\n",
        "@app.route('/vckt_uploads/<filename>')\n",
        "def uploaded_file(filename):\n",
        "    html_filename = f'audio_and_spectrogram_comparison_{filename}.html'\n",
        "    return render_template(html_filename)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    os.makedirs('vckt_uploads', exist_ok=True)\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "id": "FOa0qkJWlLY1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}